{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab4-Using-Convolutions.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sunbreak/codelabs-tensorflow/blob/master/Lab4-Using-Convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Yh9Fy6SigwI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "627a4de6-1ec0-4638-9d74-6b3ea36eac7e"
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print('Test loss: {}, Test accuracy: {}'.format(test_loss, test_accuracy*100))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.4997 - acc: 0.8260\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3789 - acc: 0.8641\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3388 - acc: 0.8773\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3146 - acc: 0.8851\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.2958 - acc: 0.8902\n",
            "10000/10000 [==============================] - 0s 32us/sample - loss: 0.3506 - acc: 0.8740\n",
            "Test loss: 0.35059437980651853, Test accuracy: 87.40000128746033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1WZKwz1i5vU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "4c9fa455-de77-41c3-86e0-f55b6c46d2f4"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images / 255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print('Test loss: {}, Test accuracy: {}'.format(test_loss, test_accuracy*100))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 95s 2ms/sample - loss: 0.4302 - acc: 0.8423\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 88s 1ms/sample - loss: 0.2891 - acc: 0.8939\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 87s 1ms/sample - loss: 0.2470 - acc: 0.9097\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 87s 1ms/sample - loss: 0.2129 - acc: 0.9208\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 88s 1ms/sample - loss: 0.1876 - acc: 0.9301\n",
            "10000/10000 [==============================] - 4s 426us/sample - loss: 0.2526 - acc: 0.9098\n",
            "Test loss: 0.25258463985919954, Test accuracy: 90.97999930381775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rll7yWr8tW9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4ad1c9b8-0727-4b76-d64a-52fbb323e3c2"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images / 255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=20)\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print ('Test loss: {}, Test accuracy: {}'.format(test_loss, test_accuracy*100))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 243,786\n",
            "Trainable params: 243,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 86s 1ms/sample - loss: 0.4368 - acc: 0.8397\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.2923 - acc: 0.8932\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 90s 1ms/sample - loss: 0.2477 - acc: 0.9084\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 88s 1ms/sample - loss: 0.2145 - acc: 0.9193\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 85s 1ms/sample - loss: 0.1899 - acc: 0.9291\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 84s 1ms/sample - loss: 0.1651 - acc: 0.9379\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.1472 - acc: 0.9439\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.1290 - acc: 0.9507\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 84s 1ms/sample - loss: 0.1124 - acc: 0.9566\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0989 - acc: 0.9623\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0871 - acc: 0.9673\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 84s 1ms/sample - loss: 0.0765 - acc: 0.9708\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0722 - acc: 0.9725\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 82s 1ms/sample - loss: 0.0605 - acc: 0.9770\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 82s 1ms/sample - loss: 0.0556 - acc: 0.9788\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0510 - acc: 0.9808\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0449 - acc: 0.9833\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 82s 1ms/sample - loss: 0.0405 - acc: 0.9844\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 82s 1ms/sample - loss: 0.0415 - acc: 0.9846\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 82s 1ms/sample - loss: 0.0359 - acc: 0.9865\n",
            "10000/10000 [==============================] - 4s 400us/sample - loss: 0.4893 - acc: 0.9116\n",
            "Test loss: 0.4893146967999637, Test accuracy: 91.15999937057495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpM_2f21vWxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images = test_images/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYx-6ywY22AR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  #Add another convolution\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  #Now flatten the output. After this you'll just have the same DNN structure as the non convolutional version\n",
        "  tf.keras.layers.Flatten(),\n",
        "  #The same 128 dense layers, and 10 output layers as in the pre-convolution example:\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwsg5-Ky3SVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fec22207-a46f-4826-9dd7-ce0bd222b23a"
      },
      "source": [
        "print(test_labels[:100])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
            " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
            " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAfNZCbN3jyl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "ab8ddb29-4b2d-4124-9a4a-cef80a71f2e5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f, axarr = plt.subplots(3,4)\n",
        "FIRST_IMAGE=0\n",
        "SECOND_IMAGE=23\n",
        "THIRD_IMAGE=28\n",
        "CONVOLUTION_NUMBER = 6\n",
        "from tensorflow.keras import models\n",
        "layer_outputs = [layer.output for layer in model.layers]\n",
        "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
        "for x in range(0,4):\n",
        "  f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[0,x].grid(False)\n",
        "  f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[1,x].grid(False)\n",
        "  f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
        "  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "  axarr[2,x].grid(False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD7CAYAAAC2a1UBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPi7N9wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pqiR-Ni3tR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}